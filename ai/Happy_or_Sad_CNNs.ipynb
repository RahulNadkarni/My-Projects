{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zwh60FPqoutA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Image Classification using Convolutional Neural Networks\n",
        "\n",
        "Rahul Nadkarni\n"
      ],
      "metadata": {
        "id": "l216gqmNo1IX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os"
      ],
      "metadata": {
        "id": "vyZ149hQ_LQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the GPU to train the model faster"
      ],
      "metadata": {
        "id": "TRVJ8nZvo8-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus: #Limit memory growth\n",
        "  tf.config.experimental.set_memory_growth(gpu,True)"
      ],
      "metadata": {
        "id": "LnEa1Ny8_Plq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import imghdr\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "ZT90UyHe_xZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EzYeAYbZtAcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the data files from google drive - Colab Notebook"
      ],
      "metadata": {
        "id": "cQ2DYXHmpCI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive/data'"
      ],
      "metadata": {
        "id": "vX3omjb3CI5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WagJu4b_CpO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look for these files in the data folders"
      ],
      "metadata": {
        "id": "ClEWw3lDprQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_exts = ['jpeg','jpg','bmp','png']"
      ],
      "metadata": {
        "id": "aYSOIZ2oCOZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_exts[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7UkkscbrCqO_",
        "outputId": "083c2bc7-98e9-41a6-d675-b164d9672b8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bmp'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the image"
      ],
      "metadata": {
        "id": "Ga9mQ3oJpvhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(os.path.join('/content/drive/MyDrive/data','happy','smile.woman_.jpg'))"
      ],
      "metadata": {
        "id": "EHQqtB8wEKdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(length, width, dimensions(colors)) [link text](https://)"
      ],
      "metadata": {
        "id": "90z3tPoypxsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "uAE6xm_XEb5o",
        "outputId": "616e0aed-01ce-402f-f8b3-903029036f29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'shape'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-7935669c826d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocessing"
      ],
      "metadata": {
        "id": "fZBD7--Urb47"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the BGR file to RGB"
      ],
      "metadata": {
        "id": "0RpmEgH0p1Wa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "Cx67dtbREixN",
        "outputId": "24ad876e-ddb5-4303-dd63-76666f2e77e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "OpenCV(4.8.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-15acfeec493b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove all image files that are not in the supported format list."
      ],
      "metadata": {
        "id": "Thb-A23Erfg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for image_class in os.listdir(data_dir):\n",
        "  for image in os.listdir(os.path.join(data_dir,image_class)):\n",
        "    image_path = os.path.join(data_dir,image_class,image)\n",
        "    try:\n",
        "      img = cv2.imread(image)\n",
        "      tip = imghdr.what(image_path)\n",
        "      if tip not in image_exts:\n",
        "        print(\"Image not in ext list {}\".format(image_path))\n",
        "        os.remove(image_path)\n",
        "    except Exception as e:\n",
        "      print(\"Issue with image {}\".format(image_path))"
      ],
      "metadata": {
        "id": "_kqX-ftODgdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.data.Dataset"
      ],
      "metadata": {
        "id": "cs9DfDCGFLK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "Z_qe2r8qFtgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = tf.keras.utils.image_dataset_from_directory('/content/drive/MyDrive/data')"
      ],
      "metadata": {
        "id": "i8rBAexkFvZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model using batches"
      ],
      "metadata": {
        "id": "5p83oIFkrqM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_iterator = data.as_numpy_iterator() #loop through it"
      ],
      "metadata": {
        "id": "bbceaCuMF6k8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = data_iterator.next() #grab a batch - images and labels"
      ],
      "metadata": {
        "id": "nY0OlHsSGNNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch[1] #happy is 0, sad is 1"
      ],
      "metadata": {
        "id": "J1m3r5CEG503"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax = plt.subplots(ncols = 4,figsize=(20,20))\n",
        "for idx, img in enumerate(batch[0][:4]):\n",
        "  ax[idx].imshow(img.astype(int))\n",
        "  ax[idx].title.set_text(batch[1][idx])"
      ],
      "metadata": {
        "id": "d010pGTjG9CG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform a scaled transformation on the data - convert the value of x to a value between 0 and 1."
      ],
      "metadata": {
        "id": "hztd74flr1D4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.map(lambda x,y:(x/255,y))\n",
        "#performs the scaled transformation in the pipeline"
      ],
      "metadata": {
        "id": "jRAxNA_9ILOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "rvsRgRGoIdQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "id": "BqHfwf-HJVxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Train, Test, Validation Splits\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1OomzRT8r9PX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(len(data)*.7)\n",
        "val_size = int(len(data)* .2)\n",
        "test_size = int(len(data)*.1) + 1"
      ],
      "metadata": {
        "id": "hmZJ9lryJZrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size+val_size+test_size"
      ],
      "metadata": {
        "id": "1F8HXlGyJ7JF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = data.take(train_size) #how much data we take in this partition\n",
        "val = data.skip(train_size).take(val_size) #skip the batches we already allocated and take the remaining for val size\n",
        "test = data.skip(train_size + val_size).take(test_size) #everything left over\n"
      ],
      "metadata": {
        "id": "JyYmmllnJjiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test)"
      ],
      "metadata": {
        "id": "_sFshQBtKu2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating the Model"
      ],
      "metadata": {
        "id": "cg2eW9vHsHAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential #functional for multiple inputs outputs -> not for this project\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D,Dense,Flatten,Dropout"
      ],
      "metadata": {
        "id": "Px2T5VThOcoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n"
      ],
      "metadata": {
        "id": "8yBfkQHbOr5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(16,(3,3),1,activation='relu',input_shape = (256,256,3)))\n",
        "#16 filters 3x3 - stride of 1 pixel\n",
        "#relu activation - pass output of convolution to relu\n",
        "model.add(MaxPooling2D()) #take the max value and condense\n",
        "\n",
        "model.add(Conv2D(32,(3,3),1,activation = 'relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(32,(3,3),1,activation = 'relu'))\n",
        "\n",
        "model.add(Flatten())\n",
        "#flatten the matrix\n",
        "#Fully Connected Layers\n",
        "model.add(Dense(256,activation = 'relu')) # 256 neurons\n",
        "model.add(Dense(1,activation = 'sigmoid')) #single dense layer and one output -> sigmoid"
      ],
      "metadata": {
        "id": "1SSOg3V5T8Ps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile('adam',loss=tf.losses.BinaryCrossentropy(),metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Ezq2dCQhV2gP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "Pphh8plRWKIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FRL-gk4qGYKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "keras.utils.plot_model(model,to_file='plot.png',show_layer_names = True)"
      ],
      "metadata": {
        "id": "ZystbsxGVIrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logdir = '/content/drive/MyDrive/logs'"
      ],
      "metadata": {
        "id": "sTRCwzuBWupd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logdir)\n",
        "#create a checkpoint"
      ],
      "metadata": {
        "id": "Fs2Lv1PnXBkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr = model.fit(train,epochs=20,validation_data=val,callbacks = [tensorboard_callback])"
      ],
      "metadata": {
        "id": "3lncDcGdXR9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr.history"
      ],
      "metadata": {
        "id": "uy8DPnV8Y_t9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Results"
      ],
      "metadata": {
        "id": "GyoaGNM7sQGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(tr.history['loss'],color ='blue',label = 'loss')\n",
        "plt.plot(tr.history['val_loss'],color='orange',label='val_loss')\n",
        "fig.suptitle('Loss',fontsize=20)\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KHdqBFdDZRQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(tr.history['accuracy'],color ='blue',label = 'accuracy')\n",
        "plt.plot(tr.history['val_accuracy'],color='orange',label='val_accuracy')\n",
        "fig.suptitle('Accuracy',fontsize=20)\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9LdprjSzZrkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test the Model"
      ],
      "metadata": {
        "id": "QY6CAXbksSob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "metadata": {
        "id": "tq3xCL-McP7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread('/content/drive/MyDrive/data/happy/Travis-Bradberry-Happy.jpg')\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eiXO6R7GcRzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resize = tf.image.resize(img,(256,256))\n",
        "plt.imshow(resize.numpy().astype(int))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "npT4a2mrcYTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = model.predict(np.expand_dims(resize/255,0))"
      ],
      "metadata": {
        "id": "XiafkUCUcf4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat"
      ],
      "metadata": {
        "id": "tysGVmkucmN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if yhat > 0.5:\n",
        "  print(f'Predicted class is sad')\n",
        "else:\n",
        "  print(f'Predicted class is happy')"
      ],
      "metadata": {
        "id": "clwx8lchcmsP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}